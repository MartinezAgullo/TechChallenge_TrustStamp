{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23dc43ea",
   "metadata": {
    "id": "23dc43ea"
   },
   "source": [
    "# Land use and Land Cover Classification\n",
    "\n",
    "The availability of free satellite data has increased its use in several applications in the domains of agriculture, disaster recovery, climate change, urban development, or environmental monitoring can be realized. However, to fully utilize the data for the previously mentioned domains, first satellite images must be processed and transformed into structured semantics. One type of such fundamental semantics is Land Use and Land Cover Classification. The aim of land use and land cover classification is to automatically provide labels describing the represented physical land type or how a land area is used (e.g., residential, industrial)\n",
    "\n",
    "A satellite image dataset for the task of land use and land cover classification was presented in [[1]](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8519248). The EuroSAT dataset is based on Sentinel-2 satellite images and consists of 27,000 labeled images with a total of 10 different classes listed below where the patches are 64x64 pixels each.\n",
    "\n",
    "![alt text](./Images/dataset.png \"The EuroSAT Dataset\")\n",
    "\n",
    "In this assignment you are going to use the optical bands of Sentinel-2 which are computed by combining the bands red (B04), green (B03) and blue (B02) from the Sentinel-2 product. More information about the Sentinel-2 bands can be found [here](https://sentinels.copernicus.eu/web/sentinel/user-guides/sentinel-2-msi/resolutions/spatial). You will then train different Convolutional Neural Network (CNN) models to classify every 64x64 patches in one of the following classes:\n",
    "\n",
    "1. AnnualCrop\n",
    "2. Forest\n",
    "3. Herbaceous Vegetation\n",
    "4. Highway\n",
    "5. Industrial\n",
    "6. Pasture\n",
    "7. Permanent Crop\n",
    "8. Residential\n",
    "9. River\n",
    "10. SeaLake\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c122de36",
   "metadata": {
    "id": "c122de36"
   },
   "source": [
    "## Instructions\n",
    "The EuroSAT dataset is based on Sentinel-2 satellite images and consists of 27,000 labeled images with a total of 10 different classes. The dataset is structured as follows:\n",
    "1. `train.txt`: this file contains a list of images that will be used to train the Convolutional Neural Network (CNN) models.\n",
    "2. `test.txt`: this file contains a list of images that will be used to test the Convolutional Neural Network (CNN) models.\n",
    "3. A list of 10 folders, each one containing the images pertaining to each class.\n",
    "\n",
    "All code needs to be developed in Python 3 and run on a Ubuntu 20.04 environment or later versions of Ubuntu. The student is requested send the jupyter notebook using the template provided. Any textual or visual information and equations that the student might need to convey is expected to be written using the markdown language within the same Juputer Notebook. The Juputer Notebook should be named as follows\n",
    "\n",
    "`name-surname.ipynb`\n",
    "\n",
    "The list of packages that are allowed for this assignment are: `matplotlib`, `os`, `numpy`, `torch`, `open-cv`, `torchvision` and any other packages agreed with the lecturer.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58f06d9",
   "metadata": {
    "id": "f58f06d9"
   },
   "source": [
    "## Assignment\n",
    "\n",
    "**Q1:** A lot of effort in solving any machine learning and computer vision problem goes into preparing the data. PyTorch provides a simple mechanism to define a custom dataset using `torch.utils.data.Dataset`, which is an abstract class representing a dataset. Your custom dataset should inherit `Dataset` and override the following methods:\n",
    "\n",
    "- `__init__` so that it initializes the dataset\n",
    "- `__len__` so that len(dataset) returns the size of the dataset.\n",
    "- `__getitem__` to support the indexing such that dataset[i] can be used to get i-th sample.\n",
    "\n",
    "\n",
    "Write a class `DataLoaderClassification` that can be used to\n",
    "- load the list of image filenames and the corresponding lables in two lists in `__init__`\n",
    "- load a batch of images and corresponding lables when one calls `__getitem__`\n",
    "- returns the length of the dataset using `__len__`\n",
    "\n",
    "Write the code in one or more cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "eb72341b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "68f7118b",
   "metadata": {
    "id": "68f7118b"
   },
   "outputs": [],
   "source": [
    "class DataLoaderClassification(Dataset):\n",
    "    def __init__(self, data_dir, file_list_path):\n",
    "        # Args:\n",
    "        #    data_dir :: Path to the directory containing image subfolders.\n",
    "        #    file_list_path :: Path to the text file containing image paths (e.g., train.txt or test.txt).\n",
    "\n",
    "        self.data_dir = data_dir        \n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "        \n",
    "        with open(file_list_path, 'r') as f:\n",
    "            for line in f:\n",
    "                line = line.strip()\n",
    "                if line:\n",
    "                    updated_path = line.replace('EuroSAT/', '')  \n",
    "                    self.image_paths.append(updated_path)\n",
    "                    \n",
    "                    label = os.path.split(updated_path)[0].replace('./Data/', '')  \n",
    "                    self.labels.append(label)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_full_path = self.image_paths[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        image = cv2.imread(img_full_path)\n",
    "        if image is None:\n",
    "            raise FileNotFoundError(f\"Image at path {img_full_path} could not be loaded.\")\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)# Convert to RGB\n",
    "\n",
    "        # image to tensor\n",
    "        transform = transforms.ToTensor()\n",
    "        image = transform(image)\n",
    "        \n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "01eb3a34",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of items in train_dataset: 21600\n",
      "Number of items in test_dataset: 5400\n",
      "Check item 7875 from train_dataset\n",
      "Image 7875 -> Shape: torch.Size([3, 64, 64]), Label: Residential\n"
     ]
    }
   ],
   "source": [
    "data_dir = 'Data'\n",
    "train_file_list = 'Data/train.txt'\n",
    "test_file_list = 'Data/test.txt'\n",
    "\n",
    "train_dataset = DataLoaderClassification(data_dir=data_dir, file_list_path=train_file_list)\n",
    "test_dataset  = DataLoaderClassification(data_dir=data_dir, file_list_path=test_file_list)\n",
    "\n",
    "print(f\"Number of items in train_dataset: {len(train_dataset)}\")\n",
    "print(f\"Number of items in test_dataset: {len(test_dataset)}\")\n",
    "\n",
    "\n",
    "# test for getitem\n",
    "test_index = random.randint(0, 21599)\n",
    "print(f\"Check item {test_index} from train_dataset\")\n",
    "image, label = train_dataset[test_index]\n",
    "print(f\"Image {test_index} -> Shape: {image.shape}, Label: {label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f9eb1c0",
   "metadata": {
    "id": "8f9eb1c0"
   },
   "source": [
    "**Q2:** Write the code in one cell that uses the list of files included in `train.txt` and `test.txt` to create a Pytorch dataloader for the training and testing data, respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f316a1c",
   "metadata": {},
   "source": [
    "**Loading in batches**\n",
    "\n",
    "DataLoader: Shuffling while training to prevent learning parterns related to the order.\n",
    "When testing, shuffling is typically set to False to maintain the order of the test samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "9a5aad63",
   "metadata": {
    "id": "9a5aad63"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Batch 1  \n",
      "   Image batch shape: torch.Size([32, 3, 64, 64]), \n",
      "   Labels: ('HerbaceousVegetation', 'Residential', 'SeaLake', 'PermanentCrop', 'Residential', 'AnnualCrop', 'PermanentCrop', 'Residential', 'HerbaceousVegetation', 'Residential', 'Residential', 'AnnualCrop', 'Forest', 'PermanentCrop', 'HerbaceousVegetation', 'Pasture', 'PermanentCrop', 'AnnualCrop', 'HerbaceousVegetation', 'SeaLake', 'PermanentCrop', 'Forest', 'Forest', 'HerbaceousVegetation', 'AnnualCrop', 'Industrial', 'AnnualCrop', 'AnnualCrop', 'AnnualCrop', 'AnnualCrop', 'AnnualCrop', 'Highway')\n",
      "\n",
      " Batch 2  \n",
      "   Image batch shape: torch.Size([32, 3, 64, 64]), \n",
      "   Labels: ('AnnualCrop', 'River', 'Pasture', 'Highway', 'AnnualCrop', 'AnnualCrop', 'HerbaceousVegetation', 'PermanentCrop', 'AnnualCrop', 'PermanentCrop', 'Industrial', 'Forest', 'River', 'SeaLake', 'AnnualCrop', 'PermanentCrop', 'PermanentCrop', 'Pasture', 'SeaLake', 'PermanentCrop', 'Residential', 'PermanentCrop', 'SeaLake', 'Pasture', 'SeaLake', 'River', 'Highway', 'Pasture', 'HerbaceousVegetation', 'Residential', 'River', 'Pasture')\n",
      "\n",
      " Batch 3  \n",
      "   Image batch shape: torch.Size([32, 3, 64, 64]), \n",
      "   Labels: ('SeaLake', 'Forest', 'Highway', 'Highway', 'Residential', 'Pasture', 'Residential', 'SeaLake', 'Highway', 'Highway', 'Pasture', 'PermanentCrop', 'Residential', 'Residential', 'HerbaceousVegetation', 'AnnualCrop', 'Pasture', 'PermanentCrop', 'Industrial', 'Pasture', 'River', 'PermanentCrop', 'Residential', 'Forest', 'Residential', 'PermanentCrop', 'AnnualCrop', 'AnnualCrop', 'PermanentCrop', 'PermanentCrop', 'River', 'Forest')\n"
     ]
    }
   ],
   "source": [
    "#num_workers = 0   # number of subprocesses to use for data loading\n",
    "batch_size = 20   # how many samples per batch to load\n",
    "valid_size = 0.2  # percentage of training set to use as validation\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# test: Iterate through the dataset in batches\n",
    "for batch_idx, (images, labels) in enumerate(train_loader):\n",
    "    print(f\"\\n Batch {batch_idx + 1}  \\n   Image batch shape: {images.shape}, \\n   Labels: {labels}\")\n",
    "    if batch_idx == 2:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e11b3aa2",
   "metadata": {
    "id": "e11b3aa2"
   },
   "source": [
    "**Q3:** PyTorch provides the elegantly designed modules and classes, including `torch.nn`, to help you create and train neural networks. An `nn.Module` contains layers, and a method `forward(input)` that returns the output. Write the `CNN` class to define a Convolutional Neural Network (CNN) where the first convolutional layer (`conv1`) takes 3 input channels, outputs 16 output channels and has a kernel size of 5. The output of `conv1` is fed into a ReLU followed by a Max-pooling operator. The second convolutional layer in this network (`conv2`) should have 32 filters with a kernel size of 5 followed by a ReLU and a max-pooling operator. The last layer is a fully-connected layer (`fc1`) with 10 output neurons. In this code you should define the `__init__` and `forward` member functions.\n",
    "\n",
    "More information about `torch.nn` can be found [here](https://pytorch.org/tutorials/recipes/recipes/defining_a_neural_network.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "79aa9c30",
   "metadata": {
    "id": "79aa9c30"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=5)\n",
    "        self.fc1 = nn.Linear(in_features=32 * 13 * 13, out_features=10)\n",
    "\n",
    "    def forward(self, x):\n",
    "                                                     # --> 64x64x3 -->\n",
    "        x = F.relu(self.conv1(x))                    # --> 16x60x60 (kernel_size=5 without padding)\n",
    "        x = F.max_pool2d(x, kernel_size=2, stride=2) # --> 16x30x30 \n",
    "        x = F.relu(self.conv2(x))                    # --> 32x26x26 (kernel_size=5 without padding)\n",
    "        x = F.max_pool2d(x, kernel_size=2, stride=2) # --> 32x13x13\n",
    "        x = x.view(-1, 32 * 13 * 13)                 # --> 1x5408\n",
    "        x = self.fc1(x)                              # --> 1x10\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca5cacf",
   "metadata": {},
   "source": [
    "Pooling with kernel size of 2 and stride of 2 (typicall choice) -> downsamples the feature map by a factor of 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251b64c8",
   "metadata": {
    "id": "251b64c8"
   },
   "source": [
    "**Q4:** Write the code in one or more cells to train the CNN specified in **Q3**. Plot the accuracy against the number of epochs.  Save the best performing model in the folder `./Model/Simple-CNN/model.pth` and print the highest accuracy achieved after 100 epochs using the markdown language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c921e2",
   "metadata": {
    "id": "b9c921e2"
   },
   "outputs": [],
   "source": [
    "# Code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d51492",
   "metadata": {
    "id": "82d51492"
   },
   "source": [
    "**Q5:** Your role as a researcher is to improve the performance of the current neural network. Explain the architecture that provided the best performance and describe the modifications that you think provided the gain.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9283f982",
   "metadata": {
    "id": "9283f982"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0735709",
   "metadata": {
    "id": "b0735709"
   },
   "outputs": [],
   "source": [
    "# Code goes here"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
